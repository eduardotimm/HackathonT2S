# src/rater.py
import os
import json
import google.generativeai as genai

# print(f"[Debug Chave] Chave de API que o Python est√° lendo: {os.getenv('GOOGLE_API_KEY')}")
# !!! ATEN√á√ÉO: COLOQUE SUA CHAVE DE API AQUI DENTRO DAS ASPAS !!!
MINHA_CHAVE_DIRETA = "AIzaSyDF7SRy6wemtyV8CBzv0amkd4LQARXDRUs"

# Verifica√ß√£o para garantir que a chave foi inserida
if not MINHA_CHAVE_DIRETA or "SUA_CHAVE" in MINHA_CHAVE_DIRETA:
    print(
        "\n!!! ERRO DE CONFIGURA√á√ÉO: Voc√™ precisa colocar sua chave de API real na vari√°vel MINHA_CHAVE_DIRETA no arquivo rater.py !!!\n"
    )
    # Limpamos a chave para n√£o tentar usar uma chave inv√°lida
    GOOGLE_API_KEY = None
else:
    genai.configure(api_key=MINHA_CHAVE_DIRETA)
    GOOGLE_API_KEY = (
        MINHA_CHAVE_DIRETA  # Mantemos a vari√°vel para o resto do c√≥digo funcionar
    )
    
# --- Fun√ß√µes de IA ---
def executar_avaliacao_completa(metricas_brutas: dict) -> list:
    """
    Recebe as m√©tricas brutas do analyzer e monta um prompt baseado no desafio proposto
    Usa o Gemini para gerar uma justificativa textual para uma nota.
    retorna uma lista de avalia√ß√µes.
    """
    if not GOOGLE_API_KEY:
        return []
    
    readme_preview = metricas_brutas.get('conteudo_readme','')[:4000]
    try:
        model = genai.GenerativeModel("gemini-2.5-pro")

        prompt = f"""
        ## FUN√á√ÉO E OBJETIVO
        Voc√™ √© especialista em arquitetura, engenharia e qualidade de Software, pragm√°tico e t√©cnico da empresa de Software T2S Labs. Seu objetivo √© analisar aplica√ß√µes e prover um arquivo JSON bem estruturado contendo avalia√ß√µes e um feedback 'insightful' educacional e profundo. Sua revis√£o deve ser severa, referenciando os dados espec√≠ficos para justificar suas conclus√µes. Seja Direto, justo e claro e sempre gere um feedback construtivo. 
        ## CONTEXTO
        Voc√™ estar√° avaliando um projeto com as seguintes m√©tricas:
        - Total de Arquivos:{metricas_brutas.get('total_arquivos',0)}
        - Arquivos de Teste encontrados:{metricas_brutas.get('contagem_testes',0)}
        - Conte√∫do README.md (primeiros 4000 caracteres):"{readme_preview}"
        
        ## SUA TAREFA
        Voc√™ estar√° avaliando os projetos de acordo com esses 2 crit√©rios principais de 0 a 100 tendo a pontua√ß√£o igualmente distribuida entre eles, cuja soma dever√° ser a nota final do projeto.
        1. Qualidade de Engenharia de Software:
            - Adequa√ß√£o Funcional: An√°lise do README.md e da estrutura do
            projeto para verificar a coer√™ncia entre o que foi proposto e o que
            parece ter sido implementado.
            - Manutenibilidade: Avalia√ß√£o da clareza do c√≥digo, uso de
            coment√°rios, padroniza√ß√£o (linters) e complexidade do c√≥digo.
            -Confiabilidade: Verifica√ß√£o da exist√™ncia de su√≠tes de testes (ex:
            arquivos de teste, frameworks como Jest, PyTest, etc.).
            - Usabilidade (Clareza): An√°lise da qualidade e completude da
            documenta√ß√£o (README.md, guias de instala√ß√£o, etc.).
            - Desempenho: An√°lise da velocidade de execu√ß√£o e do consumo de
            recursos computacionais.
        2. Qualidade de Aplica√ß√£o de IA:
            - Origem e Tratamento dos Dados: An√°lise sobre como a IA √©
            alimentada (fonte de dados, pr√©-processamento).
            - T√©cnicas Aplicadas: Identifica√ß√£o das t√©cnicas de IA utilizadas (ex:
            engenharia de prompt, RAG, fine-tuning).
            - Estrat√©gia de Valida√ß√£o e Escolha de Modelos: Verifica√ß√£o se h√°
            justificativa para a escolha do LLM e como a solu√ß√£o √© validada.
            - M√©tricas de Avalia√ß√£o, Custo e Desempenho: An√°lise de como a
            equipe mede o sucesso de sua IA e considera√ß√µes sobre
            custo/efici√™ncia.
            - Seguran√ßa e Governan√ßa: Avalia√ß√£o de riscos (inje√ß√£o de prompt) e
            implementa√ß√£o de mecanismos de seguran√ßa (guardrails).
        Escreva de forma profissional, e construtiva uma justificativa para essa pontua√ß√£o. comece com um emoji apropriado: (üèÜ, ‚úÖ, ‚ö†Ô∏è, ‚ùå, üö®).
        N√£o √© necess√°rio a presen√ßa de formalidades, como apresenta√ß√µes. Sua analise ir√° para um relat√≥rio ent√£o seja direto em suas respotas. Avalie o projeto, levantes seus pontos fortes e fracos. Gere suas notas e justificativas e pronto.
        Se atente tamb√©m para seguir a numera√ß√£o dos t√≥picos de forma correta.

        ## RETORNOS
        - Sua resposta completa DEVE ser um array JSON v√°lido (uma lista de objetos) e NADA MAIS.
        - N√£o inclua marcadores de markdown como ```json ou ```.
        - Cada objeto no array DEVE ter exatamente 3 chaves, todas em min√∫sculas: "criterio" (string), "nota" (integer), e "justificativa" (string).
        - As respostas devem estar em pt-br
        - O json deve conter SOMENTE os dois crit√©rios citados, Qualidade de Engenharia de Software e Qualidade de Aplica√ß√£o de IA.
        - A justificativa deve conter uma breve explica√ß√£o sobre cada um dos subcrit√©rios, e por que recebeu a nota.

        ATEN√á√ÉO caso um dos pontos n√£o esteja presente na avalia√ß√£o, aponte o que est√° faltando, mostre os malef√≠cios dessa aus√™ncia e as raz√µes pela qual ela DEVE ser implementada.

        ## Seu Cliente
        Sua an√°lise ser√° recebida por desenvolvedores recrutadores, buscando por talentos no mercado de trabalho atrav√©s de um hackathon
        """
        response = model.generate_content(prompt)
        #Limpeza da String JSON
        cleaned_response = response.text.strip().replace("```json","").replace("```","")

        #Decodifica a string JSON em uma estrutura de dados Python
        return json.loads(cleaned_response)
    
    except Exception as e:
        print(f"   - [IA] ERRO ao chamar a API do Gemini: {e}")
        return "Falha ao gerar a justificativa da IA."


# --- Fun√ß√µes de C√°lculo de Nota ---
def calcular_nota_de_testes(metricas_brutas: dict) -> int:
    contagem_testes = metricas_brutas.get("contagem_testes", 0)
    total_arquivos = metricas_brutas.get("total_arquivos", 0)
    if total_arquivos == 0:
        return 0
    percentual_de_testes = (contagem_testes / total_arquivos) * 100
    meta_percentual_excelente = 30.0
    nota = int(min(100, (percentual_de_testes / meta_percentual_excelente) * 100))
    return nota


# --- Bloco de Teste ATUALIZADO ---
if __name__ == '__main__':
    print("--- Testando Rater Multi-Crit√©rio com IA ---")

    if not GOOGLE_API_KEY:
        print("Execu√ß√£o de teste interrompida. Configure a GOOGLE_API_KEY primeiro.")
    else:
        # Simula a sa√≠da do analyzer para o reposit√≥rio 'Flask'
        metricas_de_teste = {
            'total_arquivos': 326, 
            'contagem_testes': 89, 
            'conteudo_readme': "# Flask\n\nFlask is a lightweight WSGI web application framework. It is designed to make getting started quick and easy, with the ability to scale up to complex applications..."
        }
        
        print(f"M√©tricas de Teste (Simuladas): {metricas_de_teste.get('contagem_testes')} testes em {metricas_de_teste.get('total_arquivos')} arquivos.\n")

        avaliacoes_ia = executar_avaliacao_completa(metricas_de_teste)
    
        if avaliacoes_ia:
            print("‚úÖ Sucesso! IA retornou as seguintes avalia√ß√µes estruturadas:")
            # Imprime o JSON de forma leg√≠vel
            print(json.dumps(avaliacoes_ia, indent=2, ensure_ascii=False))
        else:
            print("\n‚ùå Falha ao obter a avalia√ß√£o da IA.")
